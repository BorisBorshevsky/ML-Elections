{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before outliar detacction: 10000\n",
      "After outliar detacction: 8543\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 8543 entries, 0 to 9997\n",
      "Data columns (total 53 columns):\n",
      "Vote                                             8543 non-null float64\n",
      "Occupation_Satisfaction                          8543 non-null float64\n",
      "Avg_monthly_expense_when_under_age_21            8543 non-null float64\n",
      "AVG_lottary_expanses                             8543 non-null float64\n",
      "Avg_Satisfaction_with_previous_vote              8543 non-null float64\n",
      "Looking_at_poles_results                         8543 non-null float64\n",
      "Garden_sqr_meter_per_person_in_residancy_area    8543 non-null float64\n",
      "Married                                          8543 non-null float64\n",
      "Gender                                           8543 non-null float64\n",
      "Voting_Time                                      8543 non-null float64\n",
      "Financial_balance_score_(0-1)                    8543 non-null float64\n",
      "%Of_Household_Income                             8543 non-null float64\n",
      "Avg_government_satisfaction                      8543 non-null float64\n",
      "Avg_education_importance                         8543 non-null float64\n",
      "Avg_environmental_importance                     8543 non-null float64\n",
      "Avg_Residancy_Altitude                           8543 non-null float64\n",
      "Yearly_ExpensesK                                 8543 non-null float64\n",
      "%Time_invested_in_work                           8543 non-null float64\n",
      "Yearly_IncomeK                                   8543 non-null float64\n",
      "Avg_monthly_expense_on_pets_or_plants            8543 non-null float64\n",
      "Avg_monthly_household_cost                       8543 non-null float64\n",
      "Will_vote_only_large_party                       8543 non-null float64\n",
      "Phone_minutes_10_years                           8543 non-null float64\n",
      "Avg_size_per_room                                8543 non-null float64\n",
      "Weighted_education_rank                          8543 non-null float64\n",
      "%_satisfaction_financial_policy                  8543 non-null float64\n",
      "Avg_monthly_income_all_years                     8543 non-null float64\n",
      "Last_school_grades                               8543 non-null float64\n",
      "Age_group                                        8543 non-null float64\n",
      "Number_of_differnt_parties_voted_for             8543 non-null float64\n",
      "Political_interest_Total_Score                   8543 non-null float64\n",
      "Number_of_valued_Kneset_members                  8543 non-null float64\n",
      "Overall_happiness_score                          8543 non-null float64\n",
      "Num_of_kids_born_last_10_years                   8543 non-null float64\n",
      "Financial_agenda_matters                         8543 non-null float64\n",
      "split                                            8543 non-null int64\n",
      "Is_Most_Important_Issue_Healthcare               8543 non-null float64\n",
      "Is_Most_Important_Issue_Environment              8543 non-null float64\n",
      "Is_Most_Important_Issue_Social                   8543 non-null float64\n",
      "Is_Most_Important_Issue_Military                 8543 non-null float64\n",
      "Is_Most_Important_Issue_Financial                8543 non-null float64\n",
      "Is_Most_Important_Issue_Education                8543 non-null float64\n",
      "Is_Most_Important_Issue_Other                    8543 non-null float64\n",
      "Is_Most_Important_Issue_Foreign_Affairs          8543 non-null float64\n",
      "Is_Occupation_Hightech                           8543 non-null float64\n",
      "Is_Occupation_Public_Sector                      8543 non-null float64\n",
      "Is_Occupation_Services_or_Retail                 8543 non-null float64\n",
      "Is_Occupation_Student_or_Unemployed              8543 non-null float64\n",
      "Is_Occupation_Industry_or_other                  8543 non-null float64\n",
      "Is_Main_transportation_Public_or_other           8543 non-null float64\n",
      "Is_Main_transportation_Motorcycle_or_truck       8543 non-null float64\n",
      "Is_Main_transportation_Foot_or_bicycle           8543 non-null float64\n",
      "Is_Main_transportation_Car                       8543 non-null float64\n",
      "dtypes: float64(52), int64(1)\n",
      "memory usage: 3.5 MB\n",
      "Removing features with low variance -  \t[]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pylab as p\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Tree-based feature selection\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif, mutual_info_classif\n",
    "\n",
    "\n",
    "redundant_features = []\n",
    "useful_features = []\n",
    "\n",
    "def import_data():\n",
    "    # For .read_csv, always use header=0 when you know row 0 is the header row\n",
    "    df = pd.read_csv(\"./data/ElectionsData-full.csv\", header=0)\n",
    "\n",
    "    df['split'] = 0\n",
    "#     indices = KFold(n=len(df), n_folds=5, shuffle=True)._iter_test_indices()\n",
    "#     df['split'][indices.next()] = 1\n",
    "#     df['split'][indices.next()] = 2\n",
    "#     raw_data = df.copy()\n",
    "\n",
    "#     raw_data[raw_data['split'] == 0].drop('split', axis=1).to_csv('./data/output/raw_train.csv', index=False, sep=',')\n",
    "#     raw_data[raw_data['split'] == 1].drop('split', axis=1).to_csv('./data/output/raw_test.csv', index=False, sep=',')\n",
    "#     raw_data[raw_data['split'] == 2].drop('split', axis=1).to_csv('./data/output/raw_validation.csv', index=False)\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def export_transformed_data(_df):\n",
    "    _df[_df['split'] == 0].drop('split', axis=1).to_csv('./data/output/processed_train.csv', index=False)\n",
    "    _df[_df['split'] == 1].drop('split', axis=1).to_csv('./data/output/processed_test.csv', index=False)\n",
    "    _df[_df['split'] == 2].drop('split', axis=1).to_csv('./data/output/processed_validation.csv', index=False)\n",
    "\n",
    "\n",
    "def group_features(_df):\n",
    "    _df = _df.dropna()\n",
    "    all_features = _df.drop(['Vote', 'split'], axis=1).columns\n",
    "    categorical_features = _df.drop(['Vote', 'split'], axis=1).select_dtypes(include=[\"object\"])\n",
    "    numeric_features = _df.drop(['Vote', 'split'], axis=1).select_dtypes(exclude=[\"object\"])\n",
    "\n",
    "    return [all_features, categorical_features, numeric_features]\n",
    "\n",
    "\n",
    "def fill_numeric_features(_df, features):\n",
    "    for f in features:\n",
    "        _df[f].fillna(_df[f].median(), inplace=True)\n",
    "\n",
    "\n",
    "def fill_categorical_features(_df, features):\n",
    "    for f in features:\n",
    "        _df[f].fillna(_df[f].value_counts().idxmax(), inplace=True)\n",
    "\n",
    "\n",
    "def transform_categorical_features(_df, features):\n",
    "    for f in features:\n",
    "        _df[f] = _df[f].astype(\"category\")\n",
    "        _df[f + \"_Int\"] = _df[f].cat.rename_categories(range(_df[f].nunique())).astype(int).astype(float)\n",
    "        _df.loc[_df[f].isnull(), f + \"_Int\"] = np.nan  # fix NaN conversion3\n",
    "\n",
    "\n",
    "def transform_label(_df, label):\n",
    "    _df[label] = _df[label].astype(\"category\").cat.rename_categories(range(_df[label].nunique())).astype(int).astype(float)\n",
    "\n",
    "def outliar_detection(_df, features):\n",
    "    # Outliar detection\n",
    "    threshold = 3\n",
    "    for f in numeric_features:\n",
    "        std = _df[f].std()\n",
    "        mean = _df[f].mean()\n",
    "        _df = _df[_df[f].between(mean - threshold * std, mean + threshold * std)]\n",
    "    return _df\n",
    "\n",
    "def scale_numeric(_df, features):\n",
    "    for f in features:\n",
    "        _df[f] = (_df[f] - _df[f].min()) / (_df[f].max() - _df[f].min())\n",
    "\n",
    "\n",
    "def transform_bool(_df, name):\n",
    "    _df[name] = _df[name].map({'No': -1, \"Maybe\": 0, 'Yes': 1}).astype(int).astype(float)\n",
    "\n",
    "def transform_category(_df, name):\n",
    "    redundant_features.append(name)\n",
    "    for cat in df[name].unique():\n",
    "        _df[\"Is_\" + name + \"_\" + cat] = (_df[name] == cat).astype(int).astype(float)\n",
    "    del _df[name]\n",
    "\n",
    "        \n",
    "def transform_manual(_df):\n",
    "    _df[\"Age_group\"] = _df[\"Age_group\"].map({'Below_30': 0, '30-45': 1, '45_and_up': 2}).astype(float)\n",
    "    _df[\"Voting_Time\"] = _df[\"Voting_Time\"].map({'By_16:00': 0, 'After_16:00': 1}).astype(float)\n",
    "    _df[\"Gender\"] = _df[\"Gender\"].map({'Male': -1, 'Female': 1}).astype(float)\n",
    "    \n",
    "    \n",
    "    transform_bool(_df, \"Looking_at_poles_results\")\n",
    "    transform_bool(_df, \"Married\")\n",
    "    transform_bool(_df, \"Financial_agenda_matters\")\n",
    "    transform_bool(_df, \"Will_vote_only_large_party\")\n",
    "    transform_category(_df, \"Most_Important_Issue\")\n",
    "    transform_category(_df, \"Occupation\")\n",
    "    transform_category(_df, \"Main_transportation\")\n",
    "\n",
    "def to_np_array(_df):\n",
    "    df_data_X = _df.drop(['split','Vote'], axis=1).values\n",
    "    df_data_Y = _df.Vote.values\n",
    "    features_list = _df.drop(['split','Vote'], axis=1).columns\n",
    "    return [df_data_X, df_data_Y, features_list]\n",
    "        \n",
    "def variance_filter(data_X, features_list):\n",
    "    varsel = VarianceThreshold(threshold=0.01)\n",
    "    varsel.fit_transform(data_X)\n",
    "    featsel_idx = varsel.get_support()\n",
    "    print 'Removing features with low variance - ', '\\t', list(features_list[~featsel_idx])\n",
    "    return list(features_list[~featsel_idx])\n",
    "        \n",
    "def select_features_with_rfe(data_X, data_Y, feature_names):\n",
    "    result = []\n",
    "    \n",
    "    svc = SVC(kernel=\"linear\", C=1)\n",
    "    rfecv = RFECV(estimator=svc, step=1, cv=3, scoring='accuracy')\n",
    "    rfecv.fit(data_X, data_Y)\n",
    "\n",
    "    print(\"RFE - Optimal number of features : %d\" % rfecv.n_features_)\n",
    "    \n",
    "    for idx, val in enumerate(rfecv.get_support()):\n",
    "        if val:\n",
    "            print \"RFE - Choosing feature: \" + feature_names[idx]\n",
    "            result.append(feature_names[idx]) \n",
    "    return result\n",
    "\n",
    "def univariate_features_with_mi(data_X, data_Y, feature_names):\n",
    "    result = []\n",
    "    \n",
    "    selector = SelectPercentile(mutual_info_classif, percentile=25)\n",
    "    selector.fit(data_X, data_Y)\n",
    "\n",
    "    for idx, val in enumerate(selector.get_support()):\n",
    "        if val:\n",
    "            result.append(feature_names[idx]) \n",
    "            print \"MI - Choosing feature: \" + feature_names[idx]\n",
    "    \n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "def univariate_features_with_f_classif(data_X, data_Y, feature_names):\n",
    "    result = []\n",
    "    \n",
    "    selector = SelectPercentile(f_classif, percentile=25)\n",
    "    selector.fit(data_X, data_Y)\n",
    "\n",
    "    for idx, val in enumerate(selector.get_support()):\n",
    "        if val:\n",
    "            result.append(feature_names[idx]) \n",
    "            print \"f-classif - Choosing feature: \" + feature_names[idx]\n",
    "    \n",
    "    return result\n",
    "\n",
    "    \n",
    "def univariate_features_with_f_classif(data_X, data_Y, feature_names):\n",
    "    result = []\n",
    "    \n",
    "    selector = SelectPercentile(f_classif, percentile=25)\n",
    "    selector.fit(data_X, data_Y)\n",
    "\n",
    "    for idx, val in enumerate(selector.get_support()):\n",
    "        if val:\n",
    "            result.append(feature_names[idx]) \n",
    "            print \"f-classif - Choosing feature: \" + feature_names[idx]\n",
    "    \n",
    "    return result\n",
    "     \n",
    "def embedded_features_by_descision_tree(data_X, data_Y, feature_names):    \n",
    "    result = []\n",
    "\n",
    "    clf = ExtraTreesClassifier()\n",
    "    clf = clf.fit(data_X, data_Y)\n",
    "    tree_weights = clf.feature_importances_  \n",
    "    tree_weights /= tree_weights.max()\n",
    "    tree_booleans = tree_weights > np.percentile(tree_weights, 75)\n",
    "    for idx, val in enumerate(tree_booleans):\n",
    "        if val:\n",
    "            result.append(feature_names[idx]) \n",
    "            print \"Tree Clasifier - Choosing feature: \" + feature_names[idx]\n",
    "    \n",
    "    return result\n",
    "    \n",
    "# redundant_features = []\n",
    "# useful_features = []\n",
    "\n",
    "df = import_data()\n",
    "\n",
    "all_features, categorical_features, numeric_features = group_features(df)\n",
    "\n",
    "fill_numeric_features(df, numeric_features)\n",
    "fill_categorical_features(df, categorical_features)\n",
    "# transform_categorical_features(df, categorical_features)  # We Don't need that!!\n",
    "transform_label(df, \"Vote\")\n",
    "transform_manual(df)\n",
    "\n",
    "scale_numeric(df, numeric_features)\n",
    "print \"Before outliar detacction: \" + str(df.shape[0])\n",
    "df = outliar_detection(df, numeric_features)\n",
    "print \"After outliar detacction: \" + str(df.shape[0])\n",
    "\n",
    "df.info()\n",
    "\n",
    "\n",
    "df_data_X, df_data_Y, features_list = to_np_array(df)\n",
    "df_data_X_scaled = preprocessing.scale(df_data_X)\n",
    "\n",
    "features_to_exclude = variance_filter(df_data_X_scaled, features_list)\n",
    "redundant_features.extend(features_to_exclude)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RFE - Optimal number of features : 23\n",
      "RFE - Choosing feature: AVG_lottary_expanses\n",
      "RFE - Choosing feature: Avg_Satisfaction_with_previous_vote\n",
      "RFE - Choosing feature: Looking_at_poles_results\n",
      "RFE - Choosing feature: Garden_sqr_meter_per_person_in_residancy_area\n",
      "RFE - Choosing feature: Married\n",
      "RFE - Choosing feature: Yearly_IncomeK\n",
      "RFE - Choosing feature: Avg_monthly_expense_on_pets_or_plants\n",
      "RFE - Choosing feature: Avg_monthly_household_cost\n",
      "RFE - Choosing feature: Will_vote_only_large_party\n",
      "RFE - Choosing feature: Phone_minutes_10_years\n",
      "RFE - Choosing feature: Avg_size_per_room\n",
      "RFE - Choosing feature: Weighted_education_rank\n",
      "RFE - Choosing feature: Last_school_grades\n",
      "RFE - Choosing feature: Political_interest_Total_Score\n",
      "RFE - Choosing feature: Number_of_valued_Kneset_members\n",
      "RFE - Choosing feature: Overall_happiness_score\n",
      "RFE - Choosing feature: Is_Most_Important_Issue_Environment\n",
      "RFE - Choosing feature: Is_Most_Important_Issue_Social\n",
      "RFE - Choosing feature: Is_Most_Important_Issue_Military\n",
      "RFE - Choosing feature: Is_Most_Important_Issue_Financial\n",
      "RFE - Choosing feature: Is_Most_Important_Issue_Education\n",
      "RFE - Choosing feature: Is_Most_Important_Issue_Other\n",
      "RFE - Choosing feature: Is_Most_Important_Issue_Foreign_Affairs\n"
     ]
    }
   ],
   "source": [
    "#############################################\n",
    "good_features = select_features_with_rfe(df_data_X, df_data_Y, features_list)\n",
    "useful_features.extend(good_features)\n",
    "\n",
    "good_features = univariate_features_with_mi(df_data_X, df_data_Y, features_list)\n",
    "useful_features.extend(good_features)\n",
    "\n",
    "good_features = univariate_features_with_f_classif(df_data_X, df_data_Y, features_list)\n",
    "useful_features.extend(good_features)\n",
    "\n",
    "good_features = embedded_features_by_descision_tree(df_data_X, df_data_Y, features_list)\n",
    "useful_features.extend(good_features)\n",
    "#############################################\n",
    "useful_features = list(set(useful_features))\n",
    "useful_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def anova_filter(_df, features):\n",
    "    ret_val=set()\n",
    "    X = _df[features].values\n",
    "    Y = _df.Vote.values\n",
    "    v = f_classif(X, Y)[1]\n",
    "    i = 0\n",
    "\n",
    "    for c in features:\n",
    "        if v[i] < alpha:\n",
    "            print c + \" selected by anova with p-value: \" + str(v[i])\n",
    "            ret_val.add(c)\n",
    "        i += 1\n",
    "    return ret_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
