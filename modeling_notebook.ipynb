{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "from IPython import embed\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn.multiclass import OneVsOneClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_prepared_data():\n",
    "\tdf_train = pd.read_csv('./data/output/processed_train.csv', header=0)\n",
    "\tdf_test = pd.read_csv('./data/output/processed_test.csv', header=0)\n",
    "\tfeatures = list(set(df_train.columns) - {'Vote'})\n",
    "\ttarget = 'Vote'\n",
    "\n",
    "\tdf_train_X = df_train[features]\n",
    "\tdf_train_Y = df_train[target]\n",
    "\tdf_test_X = df_test[features]\n",
    "\tdf_test_Y = df_test[target]\n",
    "# \tlabels = {\"0\":\"Blues\",\"1\":\"Browns\",\"2\":\"Greens\",\"3\":\"Greys\",\"4\":\"Oranges\",\"5\":\"Pinks\",\"6\":\"Purples\",\"7\":\"Reds\",\"8\":\"Whites\",\"9\":\"Yellows\" }\n",
    " \tlabels = [\"Blues\",\"Browns\",\"Greens\",\"Greys\",\"Oranges\",\"Pinks\",\"Purples\",\"Reds\",\"Whites\",\"Yellows\"]\n",
    "\treturn df_train_X, df_train_Y, df_test_X, df_test_Y, labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_X, df_train_Y, df_test_X, df_test_Y, labels = load_prepared_data()\n",
    "\n",
    "train_val_data = pd.concat([df_train_X])\n",
    "features = train_val_data.values\n",
    "target = pd.concat([df_train_Y]).values\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear SVC score: 0.894135, std: 0.016005\n"
     ]
    }
   ],
   "source": [
    "clf = SVC(kernel='linear')\n",
    "scores = cross_val_score(clf, features, target, cv=15)\n",
    "print \"linear %s score: %f, std: %f\" % (clf.__class__.__name__, np.mean(scores), np.std(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC OVR Score: 0.900571, std: 0.014538\n"
     ]
    }
   ],
   "source": [
    "clf = LinearSVC(multi_class='ovr')\n",
    "scores = cross_val_score(clf, features, target, cv=15)\n",
    "print \"%s OVR Score: %f, std: %f\" % (clf.__class__.__name__,np.mean(scores), np.std(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearSVC crammer_singer Score: 0.906420, std: 0.013568\n"
     ]
    }
   ],
   "source": [
    "clf = LinearSVC(multi_class='crammer_singer')\n",
    "scores = cross_val_score(clf, features, target, cv=15)\n",
    "print \"%s crammer_singer Score: %f, std: %f\" % (clf.__class__.__name__, np.mean(scores), np.std(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OneVsOneClassifier Score: 0.919214, std: 0.014935\n"
     ]
    }
   ],
   "source": [
    "svc = LinearSVC()\n",
    "clf = OneVsOneClassifier(svc)\n",
    "scores = cross_val_score(clf, features, target, cv=15)\n",
    "print \"%s Score: %f, std: %f\" % (clf.__class__.__name__, np.mean(scores), np.std(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB Score: 0.866318\n"
     ]
    }
   ],
   "source": [
    "clf = GaussianNB()\n",
    "scores = cross_val_score(clf, features, target, cv=15)\n",
    "print \"%s Score: %f\" % (clf.__class__.__name__, np.mean(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimus splitter = 2, score = 0.925955\n",
      "minimus splitter = 3, score = 0.926707\n",
      "minimus splitter = 4, score = 0.929093\n",
      "minimus splitter = 5, score = 0.930633\n",
      "minimus splitter = 6, score = 0.928047\n",
      "minimus splitter = 7, score = 0.929036\n",
      "minimus splitter = 8, score = 0.929990\n",
      "minimus splitter = 9, score = 0.928648\n",
      "minimus splitter = 10, score = 0.928674\n",
      "minimus splitter = 11, score = 0.929825\n",
      "minimus splitter = 12, score = 0.928855\n",
      "minimus splitter = 13, score = 0.925516\n",
      "minimus splitter = 14, score = 0.925342\n",
      "minimus splitter = 15, score = 0.924767\n",
      "minimus splitter = 16, score = 0.923404\n",
      "minimus splitter = 17, score = 0.923196\n",
      "minimus splitter = 18, score = 0.922429\n",
      "minimus splitter = 19, score = 0.922043\n",
      "Best Splitter size: 5\n",
      "DecisionTreeClassifier with best splitter: 0.930633\n",
      "DecisionTreeClassifier Default score: 0.925955\n"
     ]
    }
   ],
   "source": [
    "all_scores = []\n",
    "for splitter in range(2,20):\n",
    "    clf = DecisionTreeClassifier(min_samples_split=splitter, random_state=0)\n",
    "    scores = cross_val_score(clf, features, target, cv=20)\n",
    "    score = np.mean(scores)\n",
    "    all_scores.append(score)\n",
    "    print \"minimus splitter = %d, score = %f\" % (splitter, score)\n",
    "print \"Best Splitter size: %d\" % (np.argmax(all_scores) + 2)\n",
    "print \"%s with best splitter: %f\" % (clf.__class__.__name__, all_scores[np.argmax(all_scores)])\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=0)\n",
    "scores = cross_val_score(clf, features, target, cv=20)\n",
    "score = np.mean(scores)\n",
    "print \"%s Default score: %f\"% (clf.__class__.__name__, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum splitter = 2, score = 0.946670\n",
      "minimum splitter = 3, score = 0.948827\n",
      "minimum splitter = 4, score = 0.951943\n",
      "minimum splitter = 5, score = 0.947105\n",
      "minimum splitter = 6, score = 0.947287\n",
      "minimum splitter = 7, score = 0.946150\n",
      "minimum splitter = 8, score = 0.945923\n",
      "minimum splitter = 9, score = 0.949397\n",
      "minimum splitter = 10, score = 0.944574\n",
      "minimum splitter = 11, score = 0.946851\n",
      "minimum splitter = 12, score = 0.943054\n",
      "minimum splitter = 13, score = 0.946655\n",
      "minimum splitter = 14, score = 0.945529\n",
      "minimum splitter = 15, score = 0.947304\n",
      "minimum splitter = 16, score = 0.947055\n",
      "minimum splitter = 17, score = 0.946091\n",
      "minimum splitter = 18, score = 0.942185\n",
      "minimum splitter = 19, score = 0.946858\n",
      "Best Splitter size: 4\n",
      "RandomForestClassifier with best splitter: 0.951943\n",
      "RandomForestClassifier Default score: 0.946670\n"
     ]
    }
   ],
   "source": [
    "all_scores = []\n",
    "for splitter in range(2,20):\n",
    "    clf = RandomForestClassifier(min_samples_split=splitter, random_state=0)\n",
    "    scores = cross_val_score(clf, features, target, cv=20)\n",
    "    score = np.mean(scores)\n",
    "    all_scores.append(score)\n",
    "    print \"minimum splitter = %d, score = %f\" % (splitter, score)\n",
    "print \"Best Splitter size: %d\" % (np.argmax(all_scores) + 2)\n",
    "print \"%s with best splitter: %f\" % (clf.__class__.__name__, all_scores[np.argmax(all_scores)])\n",
    "\n",
    "clf = RandomForestClassifier(random_state=0)\n",
    "scores = cross_val_score(clf, features, target, cv=20)\n",
    "score = np.mean(scores)\n",
    "print \"%s Default score: %f\"% (clf.__class__.__name__, score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minimum n_neighbors = 2, score = 0.905779\n",
      "minimum n_neighbors = 3, score = 0.916074\n",
      "minimum n_neighbors = 4, score = 0.912584\n",
      "minimum n_neighbors = 5, score = 0.919978\n",
      "minimum n_neighbors = 6, score = 0.916100\n",
      "minimum n_neighbors = 7, score = 0.915899\n",
      "minimum n_neighbors = 8, score = 0.913968\n",
      "minimum n_neighbors = 9, score = 0.914135\n",
      "minimum n_neighbors = 10, score = 0.912396\n",
      "minimum n_neighbors = 11, score = 0.909670\n",
      "minimum n_neighbors = 12, score = 0.910648\n",
      "minimum n_neighbors = 13, score = 0.907146\n",
      "minimum n_neighbors = 14, score = 0.906557\n",
      "minimum n_neighbors = 15, score = 0.905389\n",
      "minimum n_neighbors = 16, score = 0.902088\n",
      "minimum n_neighbors = 17, score = 0.901114\n",
      "minimum n_neighbors = 18, score = 0.899555\n",
      "minimum n_neighbors = 19, score = 0.898974\n",
      "Best n_neighbors size: 5\n",
      "KNeighborsClassifier with best N param: 0.919978\n"
     ]
    }
   ],
   "source": [
    "all_scores = []\n",
    "for n in range(2,20):\n",
    "    clf = KNeighborsClassifier(n_neighbors=n)\n",
    "    scores = cross_val_score(clf, features, target, cv=10)\n",
    "    score = np.mean(scores)\n",
    "    all_scores.append(score)\n",
    "    print \"minimum n_neighbors = %d, score = %f\" % (n, score)\n",
    "print \"Best n_neighbors size: %d\" % (np.argmax(all_scores) + 2)\n",
    "print \"KNeighborsClassifier with best N param: %f\" % (all_scores[np.argmax(all_scores)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron Score: 0.880244, std: 0.016177\n"
     ]
    }
   ],
   "source": [
    "clf = Perceptron(max_iter=300)\n",
    "scores = cross_val_score(clf, features, target, cv=10)\n",
    "print \"%s Score: %f, std: %f\" % (clf.__class__.__name__, np.mean(scores), np.std(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearDiscriminantAnalysis Score: 0.847154, std: 0.016647\n"
     ]
    }
   ],
   "source": [
    "clf = LinearDiscriminantAnalysis()\n",
    "scores = cross_val_score(clf, features, target, cv=10)\n",
    "print \"%s Score: %f, std: %f\" % (clf.__class__.__name__, np.mean(scores), np.std(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier Score: 0.945082, std: 0.010452\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(random_state=0)\n",
    "scores = cross_val_score(clf, features, target, cv=10)\n",
    "print \"%s Score: %f, std: %f\" % (clf.__class__.__name__, np.mean(scores), np.std(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier Score: 0.945291, std: 0.009389\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(max_features=None, random_state=0)\n",
    "scores = cross_val_score(clf, features, target, cv=10)\n",
    "print \"%s Score: %f, std: %f\" % (clf.__class__.__name__, np.mean(scores), np.std(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier Score: 0.808505, std: 0.086171\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(verbose=0, activation='relu', hidden_layer_sizes=(50, 25, 10), \n",
    "                  random_state=0, max_iter=500, solver='sgd', \n",
    "                  learning_rate='invscaling', momentum=.9,\n",
    "                  nesterovs_momentum=True, learning_rate_init=0.2)\n",
    "scores = cross_val_score(clf, features, target, cv=10)\n",
    "print \"MLPClassifier Score: %f, std: %f\" % (np.mean(scores), np.std(scores))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** DecisionTreeClassifier *****\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      Blues    0.40000   0.37037   0.38462        27\n",
      "     Browns    0.89744   0.91418   0.90573      1072\n",
      "     Greens    0.98905   0.99013   0.98959       912\n",
      "      Greys    0.93696   0.94509   0.94101       346\n",
      "    Oranges    0.88599   0.88312   0.88455       308\n",
      "      Pinks    0.85062   0.83503   0.84275       491\n",
      "    Purples    0.96595   0.95878   0.96235      1213\n",
      "       Reds    0.93949   0.94249   0.94099       313\n",
      "     Whites    0.73367   0.72277   0.72818       202\n",
      "    Yellows    0.94048   0.93676   0.93861       253\n",
      "\n",
      "avg / total    0.92301   0.92330   0.92312      5137\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(min_samples_split=5, random_state=0)\n",
    "pred = cross_val_predict(clf, features, target, cv=30)\n",
    "print \"***** %s *****\" % clf.__class__.__name__\n",
    "print classification_report(target, pred, target_names=labels, digits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** KNeighborsClassifier *****\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      Blues    0.50000   0.03704   0.06897        27\n",
      "     Browns    0.86484   0.97295   0.91572      1072\n",
      "     Greens    0.99232   0.99123   0.99177       912\n",
      "      Greys    0.86479   0.88728   0.87589       346\n",
      "    Oranges    0.89247   0.80844   0.84838       308\n",
      "      Pinks    0.94203   0.79430   0.86188       491\n",
      "    Purples    0.97930   0.97527   0.97728      1213\n",
      "       Reds    0.84384   0.89776   0.86997       313\n",
      "     Whites    0.82781   0.61881   0.70822       202\n",
      "    Yellows    0.90647   0.99605   0.94915       253\n",
      "\n",
      "avg / total    0.92093   0.92174   0.91814      5137\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors=5)\n",
    "pred = cross_val_predict(clf, features, target, cv=30)\n",
    "print \"***** %s *****\" % clf.__class__.__name__\n",
    "print classification_report(target, pred, target_names=labels, digits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** RandomForestClassifier *****\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      Blues    0.92308   0.44444   0.60000        27\n",
      "     Browns    0.89465   0.96642   0.92915      1072\n",
      "     Greens    0.99561   0.99561   0.99561       912\n",
      "      Greys    0.98802   0.95376   0.97059       346\n",
      "    Oranges    0.93016   0.95130   0.94061       308\n",
      "      Pinks    0.90562   0.82077   0.86111       491\n",
      "    Purples    0.97042   0.97362   0.97202      1213\n",
      "       Reds    0.95912   0.97444   0.96672       313\n",
      "     Whites    0.93038   0.72772   0.81667       202\n",
      "    Yellows    0.94382   0.99605   0.96923       253\n",
      "\n",
      "avg / total    0.94784   0.94744   0.94616      5137\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(min_samples_split=4, random_state=0)\n",
    "pred = cross_val_predict(clf, features, target, cv=30)\n",
    "print \"***** %s *****\" % clf.__class__.__name__\n",
    "print classification_report(target, pred, target_names=labels, digits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***** RandomForestClassifier *****\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "      Blues    0.54545   0.44444   0.48980        27\n",
      "     Browns    0.90359   0.96175   0.93177      1072\n",
      "     Greens    0.99780   0.99561   0.99671       912\n",
      "      Greys    0.98489   0.94220   0.96307       346\n",
      "    Oranges    0.90826   0.96429   0.93543       308\n",
      "      Pinks    0.89805   0.84318   0.86975       491\n",
      "    Purples    0.97107   0.96867   0.96987      1213\n",
      "       Reds    0.97419   0.96486   0.96950       313\n",
      "     Whites    0.86310   0.71782   0.78378       202\n",
      "    Yellows    0.94553   0.96047   0.95294       253\n",
      "\n",
      "avg / total    0.94437   0.94471   0.94389      5137\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(min_samples_split=4, max_features=None, random_state=0)\n",
    "pred = cross_val_predict(clf, features, target, cv=30)\n",
    "print \"***** %s *****\" % clf.__class__.__name__\n",
    "print classification_report(target, pred, target_names=labels, digits=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training DecisionTreeClassifier\n",
      "training score, mean: 0.926039\n"
     ]
    }
   ],
   "source": [
    "print \"Training DecisionTreeClassifier\"\n",
    "k_fold = RepeatedStratifiedKFold(n_splits=10)\n",
    "clf_tree = DecisionTreeClassifier(min_samples_split=5)\n",
    "a = []\n",
    "for train_indices, test_indices in k_fold.split(features, target):\n",
    "    clf_tree.fit(features[train_indices], target[train_indices])\n",
    "    a.append(clf_tree.score(features[test_indices],target[test_indices]))\n",
    "    \n",
    "print \"training score, mean: %f\"% (np.array(a).mean())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training KNeighborsClassifier\n",
      "training score, mean: 0.920734\n"
     ]
    }
   ],
   "source": [
    "print \"Training KNeighborsClassifier\"\n",
    "k_fold = RepeatedStratifiedKFold(n_splits=10)\n",
    "clf_knn = KNeighborsClassifier(n_neighbors=5)\n",
    "a = []\n",
    "for train_indices, test_indices in k_fold.split(features, target):\n",
    "    clf_knn.fit(features[train_indices], target[train_indices])\n",
    "    a.append(clf_knn.score(features[test_indices],target[test_indices]))\n",
    "    \n",
    "print \"training score, mean: %f\"% (np.array(a).mean())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RandomForestClassifier\n",
      "training score, mean: 0.942263\n"
     ]
    }
   ],
   "source": [
    "print \"Training RandomForestClassifier\"\n",
    "k_fold = RepeatedStratifiedKFold(n_splits=5, random_state=0)\n",
    "clf_random_forest = RandomForestClassifier(min_samples_split=4, max_features=None, random_state=0)\n",
    "a = []\n",
    "for train_indices, test_indices in k_fold.split(features, target):\n",
    "    clf_random_forest.fit(features[train_indices], target[train_indices])\n",
    "    a.append(clf_random_forest.score(features[test_indices],target[test_indices]))\n",
    "    \n",
    "print \"training score, mean: %f\"% (np.array(a).mean())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf = clf_random_forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "winner is party ## Purples ##\n"
     ]
    }
   ],
   "source": [
    "\n",
    "features_test = df_test_X\n",
    "target_test = df_test_Y\n",
    "pred = clf.predict(features_test)\n",
    "\n",
    "distribution = np.bincount(pred.astype('int64'))\n",
    "most_common = np.argmax(distribution)\n",
    "\n",
    "print \"winner is party ## %s ##\" % labels[most_common.astype('int')]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vote distribution\n",
      "Blues, 10.000000, 0.587199%\n",
      "Browns, 400.000000, 23.487962%\n",
      "Greens, 309.000000, 18.144451%\n",
      "Greys, 94.000000, 5.519671%\n",
      "Oranges, 104.000000, 6.106870%\n",
      "Pinks, 167.000000, 9.806224%\n",
      "Purples, 404.000000, 23.722842%\n",
      "Reds, 104.000000, 6.106870%\n",
      "Whites, 45.000000, 2.642396%\n",
      "Yellows, 66.000000, 3.875514%\n"
     ]
    }
   ],
   "source": [
    "print \"Vote distribution\"\n",
    "distribution = np.bincount(pred.astype('int64'))\n",
    "\n",
    "for index,party in enumerate(distribution):\n",
    "    print \"%s, %f, %f\"%(labels[index], distribution[index], distribution[index]/ float(target_test.size) * 100) + '%'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "      Blues       0.60      0.55      0.57        11\n",
      "     Browns       0.91      0.97      0.94       377\n",
      "     Greens       0.99      0.98      0.99       312\n",
      "      Greys       0.98      0.93      0.95        99\n",
      "    Oranges       0.87      0.93      0.90        97\n",
      "      Pinks       0.92      0.92      0.92       167\n",
      "    Purples       0.97      0.98      0.98       399\n",
      "       Reds       0.95      0.93      0.94       106\n",
      "     Whites       0.82      0.53      0.64        70\n",
      "    Yellows       0.92      0.94      0.93        65\n",
      "\n",
      "avg / total       0.94      0.94      0.94      1703\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_test_labled = target_test.map(lambda x: labels[int(x)])\n",
    "pred_test_labled = pd.DataFrame(pred).applymap(lambda x: labels[int(x)])\n",
    "\n",
    "print(classification_report(target_test_labled, pred_test_labled, target_names=labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  6,   0,   0,   0,   0,   0,   0,   0,   0,   5],\n",
       "       [  0, 364,   2,   0,   0,   4,   1,   0,   6,   0],\n",
       "       [  0,   0, 307,   0,   0,   3,   2,   0,   0,   0],\n",
       "       [  0,   0,   0,  92,   7,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   2,  90,   0,   0,   5,   0,   0],\n",
       "       [  0,  10,   0,   0,   0, 153,   2,   0,   2,   0],\n",
       "       [  0,   2,   0,   0,   0,   4, 393,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   7,   0,   0,  99,   0,   0],\n",
       "       [  0,  24,   0,   0,   0,   3,   6,   0,  37,   0],\n",
       "       [  4,   0,   0,   0,   0,   0,   0,   0,   0,  61]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "confusion_matrix(target_test_labled, pred_test_labled, labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Wrong predictions 101 out of 1703, hit rate: 94.069289%\n"
     ]
    }
   ],
   "source": [
    "pred1 = pred_test_labled.values   \n",
    "target1 = pd.DataFrame(target_test_labled).values\n",
    "\n",
    "miss_vals = []\n",
    "real_vals = []\n",
    "toples = []\n",
    "\n",
    "miss_count = 0\n",
    "for i, j in enumerate(pred1):\n",
    "    if pred1[i] != target1[i]:\n",
    "        miss_vals.append(pred1[i][0])\n",
    "        real_vals.append(target1[i][0])\n",
    "        toples.append((pred1[i][0],target1[i][0]))\n",
    "        miss_count = miss_count + 1\n",
    "\n",
    "\n",
    "print \"Total Wrong predictions %d out of %d, hit rate: %f\"% (miss_count, target1.size, 100 - miss_count/float(target1.size) * 100) + '%'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_test_labled.to_csv(\"test_predictions.csv\",header=['Vote'] ,index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
